Using ADAM_MAIN=org.bdgenomics.adam.cli.ADAMMain
Using SPARK_SUBMIT=/usr/bin/spark-submit
 XN	3166064
 AS	3166064
 YS	3086700
 XG	3166064
 XO	3166064
 XS	87059
 XM	3166064
 NM	3166064
 YT	3744814
Total: 3744814
May 7, 2016 1:19:28 PM INFO: org.apache.parquet.hadoop.ParquetInputFormat: Total input paths to process : 2
May 7, 2016 1:19:32 PM WARNING: org.apache.parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl
May 7, 2016 1:19:33 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1677068 records.
May 7, 2016 1:19:36 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
May 7, 2016 1:19:36 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 738 ms. row count = 1677068
May 7, 2016 1:20:17 PM WARNING: org.apache.parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl
May 7, 2016 1:20:17 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 2067746 records.
May 7, 2016 1:20:17 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
May 7, 2016 1:20:18 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 407 ms. row count = 2067746
May 7, 2016 1:20:54 PM WARNING: org.apache.parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl
May 7, 2016 1:20:54 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1677068 records.
May 7, 2016 1:20:54 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
May 7, 2016 1:20:54 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 171 ms. row count = 1677068
May 7, 2016 1:21:02 PM WARNING: org.apache.parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl
May 7, 2016 1:21:02 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 2067746 records.
May 7, 2016 1:21:02 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
May 7, 2016 1:21:03 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordReader: block read in memory in 102 ms. row count = 2067746
